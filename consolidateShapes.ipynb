{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])? y\n",
      "1304\n",
      "1305\n",
      "1306\n",
      "1307\n",
      "1308\n",
      "1309\n",
      "1310\n",
      "1475\n",
      "1481\n",
      "1492\n",
      "1499\n",
      "1500\n",
      "1501\n",
      "1503\n",
      "1505\n",
      "1507\n",
      "1510\n",
      "1513\n",
      "1515\n",
      "1516\n",
      "1518\n",
      "1525\n",
      "1531\n",
      "1532\n",
      "1533\n",
      "1535\n",
      "1537\n",
      "1543\n",
      "1545\n",
      "1546\n",
      "1549\n",
      "1554\n",
      "1560\n",
      "1563\n",
      "1567\n",
      "1571\n",
      "1572\n",
      "1578\n",
      "1579\n",
      "1581\n",
      "1582\n",
      "1583\n",
      "1586\n",
      "1589\n",
      "1591\n",
      "1592\n",
      "1598\n",
      "1603\n",
      "1604\n",
      "1605\n",
      "1609\n",
      "1612\n",
      "1614\n",
      "1617\n",
      "1622\n",
      "1623\n",
      "1626\n",
      "1627\n",
      "1629\n",
      "1631\n",
      "1633\n",
      "1634\n",
      "1635\n",
      "1636\n",
      "1637\n",
      "1640\n",
      "1641\n",
      "1645\n",
      "1646\n",
      "1647\n",
      "1648\n",
      "1649\n",
      "1652\n",
      "1654\n",
      "1659\n",
      "1660\n",
      "1661\n",
      "1662\n",
      "1663\n",
      "1665\n",
      "1668\n",
      "1673\n",
      "1676\n",
      "1678\n",
      "1691\n",
      "1695\n",
      "1696\n"
     ]
    }
   ],
   "source": [
    "# This script consolidates *.csv formatted output from Mindboggle software (https://mindboggle.info). \n",
    "# As written, it pulls data on area, cortical thickness (mean), travel depth (mean), and mean curvature (mean) for 62 cortical brain regions. \n",
    "# The script consolidates volumetric estimates from *.csv outputs. However, as this list is not comprehensive, we advice using the freesurfer_wmparc_labels_in_hybrid_graywhite.nii.gz output instead (a script to extract volumetric estimates from these files, may be found at https://github.com/TeddyTuresky/BrainMorphometry_DiminishedGrowth_BEANstudy_2021)\n",
    "\n",
    "\n",
    "side = 'left' # Need to also change to pull right side values\n",
    "tag = 'label' # Set to consolidate estimates from label_shapes.csv, but can also pull from sulcal_shapes.csv by renaming to 'sulcal'\n",
    "prog = 'freesurfer'# Set to examine volumes according to FreeSurfer labels, but can use ANTs labels with 'ants' \n",
    "\n",
    "import os\n",
    "import csv\n",
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "\n",
    "g = sorted(glob.glob('mindboggle-tables/*_{}_{}_shapes.csv'.format(side,tag)))\n",
    "v = sorted(glob.glob('mindboggle-tables/*_volume_per_{}_label.csv'.format(prog)))\n",
    "\n",
    "i = 0\n",
    "for file in g:\n",
    "    i += 1\n",
    "    file1 = file.split('/')[1]\n",
    "    sub = file1.split('_')[0]\n",
    "    print(sub)\n",
    "    df = pd.read_csv(file)\n",
    "    df.columns = df.columns.str.strip().str.lower().str.replace(' ', '_').str.replace(':', '')\n",
    "    area1 = df.area # This line and the three below are where you specify which out of 100 surface-based measures you wish to consolidate\n",
    "    depth1 = df.travel_depth_mean \n",
    "    curve1 = df.mean_curvature_mean\n",
    "    thick1 = df.freesurfer_thickness_mean\n",
    "    if i == 1:\n",
    "        areas = area1\n",
    "        depths = depth1\n",
    "        curves = curve1\n",
    "        thicks = thick1\n",
    "    else:\n",
    "        areas = pd.concat([areas, area1], axis=1)\n",
    "        depths = pd.concat([depths, depth1], axis=1)\n",
    "        curves = pd.concat([curves, curve1], axis=1)\n",
    "        thicks = pd.concat([thicks, thick1], axis=1)\n",
    "        \n",
    "i = 0    \n",
    "for vfile in v:\n",
    "    i += 1\n",
    "    vfile1 = vfile.split('/')[1]\n",
    "    vsub = vfile1.split('_')[0]\n",
    "    dfv = pd.read_csv(vfile)\n",
    "    dfv.columns = dfv.columns.str.strip().str.lower().str.replace(' ', '_').str.replace(':', '')\n",
    "    vol1 = dfv.volume\n",
    "    if i == 1:\n",
    "        vols = vol1\n",
    "    else:\n",
    "        vols = pd.concat([vols, vol1], axis=1)\n",
    "#print(areas)\n",
    "#print(depths)\n",
    "#print(curves)\n",
    "#print(thicks)\n",
    "\n",
    "areas.to_csv('{}_{}_shapes_areas.csv'.format(side,tag))\n",
    "depths.to_csv('{}_{}_shapes_depths.csv'.format(side,tag))\n",
    "curves.to_csv('{}_{}_shapes_curves.csv'.format(side,tag))\n",
    "thicks.to_csv('{}_{}_shapes_thicks.csv'.format(side,tag))\n",
    "vols.to_csv('{}_vols.csv'.format(prog))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
